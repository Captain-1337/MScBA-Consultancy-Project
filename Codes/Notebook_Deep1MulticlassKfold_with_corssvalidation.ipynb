{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import time\n",
    "import json\n",
    "import pickle\n",
    "import re\n",
    "import html\n",
    "import sys\n",
    "import gc\n",
    "import numpy as np\n",
    "from pandas import DataFrame\n",
    "from scipy.stats import spearmanr, pearsonr\n",
    "import os\n",
    "import gensim\n",
    "import keras\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV, KFold, StratifiedKFold\n",
    "from sklearn.preprocessing import PolynomialFeatures, scale\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "from corpora_utils import CorporaHelper,CorporaDomains, CorporaProperties\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Embedding, Input, Conv1D\n",
    "from keras.layers.wrappers import Bidirectional\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from keras.optimizers import SGD, Adagrad\n",
    "from keras.layers.convolutional import Conv1D, Conv2D\n",
    "from keras.layers.pooling import MaxPooling1D, GlobalMaxPooling1D, AveragePooling1D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.recurrent import LSTM, GRU\n",
    "from keras.preprocessing import sequence\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from nltk import word_tokenize\n",
    "from nltk import bigrams\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.corpus import sentiwordnet as swn\n",
    "from nltk.tokenize.casual import TweetTokenizer\n",
    "from keras.callbacks import TensorBoard\n",
    "from IPython.display import display, HTML\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, Flatten, Dense, Conv1D\n",
    "from keras import layers\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from corpora_utils import CorporaHelper,CorporaDomains, CorporaProperties\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "#Activate GPU\n",
    "#WARNING GPU TAKES 5 TIMES LONGER THAN CPU! With Consul Project 1\n",
    "#Check for GPU\n",
    "tf.test.is_gpu_available(\n",
    "    cuda_only=False, min_cuda_compute_capability=None\n",
    ")\n",
    "# GPU CONFIG\n",
    "config = tf.compat.v1.ConfigProto(\n",
    "    gpu_options = tf.compat.v1.GPUOptions(per_process_gpu_memory_fraction=0.8)\n",
    "    # device_count = {'GPU': 1}\n",
    ")\n",
    "config.gpu_options.allow_growth = True\n",
    "session = tf.compat.v1.Session(config=config)\n",
    "tf.compat.v1.keras.backend.set_session(session)\n",
    "sess = tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(log_device_placement=True))\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "\"\"\"\n",
    "\n",
    "try:\n",
    "    # Disable all GPUS\n",
    "    tf.config.set_visible_devices([], 'GPU')\n",
    "    visible_devices = tf.config.get_visible_devices()\n",
    "    for device in visible_devices:\n",
    "        assert device.device_type != 'GPU'\n",
    "except:\n",
    "    # Invalid device or cannot modify virtual devices once initialized.\n",
    "    pass\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Deep learning with multigenre corpus and 4 emotions\n",
    "\"\"\"\n",
    "# K-Fold variables\n",
    "num_folds = 10 # 10\n",
    "fold_runs = 1 # 3\n",
    "fold_no = 1\n",
    "\n",
    "MULTIGENRE = True\n",
    "TWITTER = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set wich corpora to use Multigenre or twitter\n",
    "use_mg_train_corpora = MULTIGENRE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "epochs = 10\n",
    "skfold = StratifiedKFold(n_splits = num_folds, random_state = 7, shuffle = True)\n",
    "acc_per_fold = []\n",
    "loss_per_fold = []\n",
    "avg_acc_per_run = []\n",
    "avg_loss_per_run = []\n",
    "create_final_model = True\n",
    "# run only final model an nto kfold\n",
    "run_final_train_only = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "train_labels = []\n",
    "train_texts = []\n",
    "test_labels = []\n",
    "test_texts = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_corpora(filepath, sep=';'):\n",
    "    print('Load: ', filepath)\n",
    "    corpora_helper = CorporaHelper(filepath, separator=sep)\n",
    "    count_joy = 0\n",
    "    count_sadness = 0\n",
    "    count_anger = 0\n",
    "    count_fear = 0\n",
    "    labels = []\n",
    "    texts = []\n",
    "    # preprocessing corpora\n",
    "    corpora_helper.translate_urls()\n",
    "    corpora_helper.translate_emoticons()\n",
    "    corpora_helper.translate_emojis()\n",
    "    corpora_helper.translate_email()\n",
    "    #corpora_helper.translate_mention()\n",
    "    corpora_helper.translate_html_tags()\n",
    "    #corpora_helper.translate_camel_case()\n",
    "    corpora_helper.translate_underscore()\n",
    "\n",
    "    corpora_helper.translate_string('-LRB-','(')\n",
    "    corpora_helper.translate_string('-RRB-',')')\n",
    "    corpora_helper.translate_string('`',\"'\") # ` to '\n",
    "    corpora_helper.translate_string(\"''\",'\"') # double '' to \"\n",
    "    corpora_helper.translate_contractions()\n",
    "    corpora_helper.translate_string(\"'\",\"\") # remove '\n",
    "    corpora_helper.translate_string(\"\\\\n\",\" \") # replace new lines with space\n",
    "\n",
    "    #corpora_helper.spell_correction()\n",
    "    corpora_helper.add_space_at_special_chars()\n",
    "    corpora_helper.translate_to_lower()\n",
    "\n",
    "    # 0 anger\n",
    "    # 1 fear\n",
    "    # 2 joy\n",
    "    # 3 sadness\n",
    "    for index, corpus in corpora_helper.get_data().iterrows():\n",
    "        if corpus[CorporaProperties.EMOTION.value] == 'anger':\n",
    "            texts.append(corpus[CorporaProperties.CLEANED_CORPUS.value])\n",
    "            labels.append(0)\n",
    "            count_anger += 1\n",
    "        elif corpus[CorporaProperties.EMOTION.value] == 'fear':\n",
    "            texts.append(corpus[CorporaProperties.CLEANED_CORPUS.value])\n",
    "            labels.append(1)\n",
    "            count_fear += 1\n",
    "        elif corpus[CorporaProperties.EMOTION.value] == 'joy':\n",
    "            texts.append(corpus[CorporaProperties.CLEANED_CORPUS.value])\n",
    "            labels.append(2)\n",
    "            count_joy += 1\n",
    "        elif corpus[CorporaProperties.EMOTION.value] == 'sadness':\n",
    "            texts.append(corpus[CorporaProperties.CLEANED_CORPUS.value])\n",
    "            labels.append(3)\n",
    "            count_sadness += 1\n",
    "    print('number of anger labels: ',count_anger)\n",
    "    print('number of fear labels: ', count_fear)\n",
    "    print('number of joy labels: ', count_joy)\n",
    "    print('number of sadness labels: ', count_sadness)\n",
    "    print('----------------------------------------------------------------------')\n",
    "    return texts, labels\n",
    "    #max_data = count_anger + count_fear + count_joy + count_sadness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load:  corpora/multigenre_450_train.csv\n",
      "number of anger labels:  405\n",
      "number of fear labels:  405\n",
      "number of joy labels:  405\n",
      "number of sadness labels:  405\n",
      "----------------------------------------------------------------------\n",
      "Load:  corpora/multigenre_450_test.csv\n",
      "number of anger labels:  45\n",
      "number of fear labels:  45\n",
      "number of joy labels:  45\n",
      "number of sadness labels:  45\n",
      "----------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "train_file = \"\"\n",
    "test_file = \"\"\n",
    "sep = ';'\n",
    "word_embeddings_path = ''\n",
    "if use_mg_train_corpora:\n",
    "    train_file = \"corpora/multigenre_450_train.csv\"\n",
    "    test_file = \"corpora/multigenre_450_test.csv\"\n",
    "    word_embeddings_path = 'custom_embeddings/multigenre_embedding.pkl'\n",
    "    sep = ';'\n",
    "else:\n",
    "    train_file = \"corpora/twitter_2000_train.csv\"\n",
    "    test_file = \"corpora/twitter_2000_test.csv\"\n",
    "    word_embeddings_path = 'twitter_embedding.pkl'\n",
    "    sep = '\\t'\n",
    "\n",
    "train_texts, train_labels = load_corpora(train_file, sep=sep)\n",
    "test_texts, test_labels = load_corpora(test_file, sep=sep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load prepared Multigenre ensemble embedding\n",
    "with open(word_embeddings_path, 'rb') as word_embeddings_file:\n",
    "    embedding_info = pickle.load(word_embeddings_file)\n",
    "max_words = 10000\n",
    "\n",
    "# Embedding helper functions\n",
    "def is_active_vector_method(string):\n",
    "    return int(string)\n",
    "    \n",
    "def get_unigram_embedding(word, word_embedding_dict, bin_string):\n",
    "    \n",
    "    if word in word_embedding_dict:\n",
    "        word_feature_embedding_dict = word_embedding_dict[word]\n",
    "        final_embedding = np.array([])\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "    for i in range(16):\n",
    "        if is_active_vector_method(bin_string[i]):\n",
    "            final_embedding = np.append(final_embedding, word_feature_embedding_dict[i])\n",
    "    \n",
    "    return final_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embedding helper functions\n",
    "def is_active_vector_method(string):\n",
    "    return int(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unigram_embedding(word, word_embedding_dict, bin_string):\n",
    "    \n",
    "    if word in word_embedding_dict:\n",
    "        word_feature_embedding_dict = word_embedding_dict[word]\n",
    "        final_embedding = np.array([])\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "    for i in range(16):\n",
    "        if is_active_vector_method(bin_string[i]):\n",
    "            final_embedding = np.append(final_embedding, word_feature_embedding_dict[i])\n",
    "    \n",
    "    return final_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#unigram_feature_string = \"1111111111111111\"\n",
    "# selecting relevant embeddings for multigenre\n",
    "if use_mg_train_corpora:\n",
    "    # Multigenre\n",
    "    unigram_feature_string = \"1001111111111101\"\n",
    "else:\n",
    "    # Twitter\n",
    "    unigram_feature_string = \"0110001111111101\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maxlen:  100\n"
     ]
    }
   ],
   "source": [
    "pre_padding = 0\n",
    "embeddings_index = embedding_info[0]\n",
    "MAX_SEQUENCE_LENGTH = embedding_info[1]\n",
    "maxlen = MAX_SEQUENCE_LENGTH\n",
    "print(\"maxlen: \",maxlen)\n",
    "#MAX_NB_WORDS = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding dimension: 1560\n"
     ]
    }
   ],
   "source": [
    "EMBEDDING_DIM = len(get_unigram_embedding(\"glad\", embedding_info[0], unigram_feature_string))\n",
    "print(\"Embedding dimension:\",EMBEDDING_DIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train an test data set\n",
    "def create_data(texts, labels, maxlen, max_words = 10000):\n",
    "    ## Create one hot encoding\n",
    "    #max_words = 10000\n",
    "    #maxlen = 100 # max. number of words in sequences\n",
    "    tokenizer = Tokenizer(num_words=max_words, filters = '')\n",
    "    tokenizer.fit_on_texts(texts)\n",
    "    sequences = tokenizer.texts_to_sequences(texts)\n",
    "\n",
    "    word_i = tokenizer.word_index\n",
    "    print ('%s unique Tokens found.' % len(word_i))\n",
    "\n",
    "    data = pad_sequences(sequences, maxlen=maxlen)\n",
    "\n",
    "    labels_arr = np.asarray(labels)\n",
    "    print('Shape of data:', data.shape)\n",
    "    print('Shape of labels:', labels_arr.shape)\n",
    "    print('-------------------------------------------')\n",
    "\n",
    "    # mix the data\n",
    "    indices = np.arange(data.shape[0])\n",
    "    np.random.shuffle(indices)\n",
    "    data = data[indices]\n",
    "    labels_arr = labels_arr[indices]\n",
    "\n",
    "    # split in train and validate\n",
    "    x_data = data\n",
    "    y_data = labels_arr\n",
    "    return x_data, y_data, word_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4965 unique Tokens found.\n",
      "Shape of data: (1620, 100)\n",
      "Shape of labels: (1620,)\n",
      "-------------------------------------------\n",
      "1143 unique Tokens found.\n",
      "Shape of data: (180, 100)\n",
      "Shape of labels: (180,)\n",
      "-------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Train an word index for embedding enrichment\n",
    "x_train, y_train, word_index = create_data(train_texts, train_labels, maxlen)\n",
    "x_train_copy = x_train.copy()\n",
    "y_train_copy = y_train.copy()\n",
    "x_test, y_test, test_word_index = create_data(test_texts, test_labels, maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EMBEDDING_DIM 1560\n",
      "input_length 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\COMMANDER\\.conda\\envs\\gputest\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:174: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\COMMANDER\\.conda\\envs\\gputest\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:191: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n"
     ]
    }
   ],
   "source": [
    "# Build Matrix\n",
    "word_embedding_matrix = list()\n",
    "word_embedding_matrix = np.zeros((max_words, EMBEDDING_DIM))\n",
    "#word_embedding_matrix.append(np.zeros(EMBEDDING_DIM))\n",
    "for word, i in word_index.items(): # sorted(word_indices, key=word_indices.get):\n",
    "    embedding_features = get_unigram_embedding(word, embedding_info[0], unigram_feature_string)\n",
    "    if i < max_words:\n",
    "        if embedding_features is not None:\n",
    "            # Words not found in embedding index will be all-zeros.\n",
    "            word_embedding_matrix[i] = embedding_features\n",
    "\n",
    "word_embedding_matrix = np.asarray(word_embedding_matrix, dtype='f')\n",
    "word_embedding_matrix = scale(word_embedding_matrix)\n",
    "\n",
    "#print('word_indices_len',word_indices_len)\n",
    "print('EMBEDDING_DIM',EMBEDDING_DIM)\n",
    "print('input_length', MAX_SEQUENCE_LENGTH + pre_padding)\n",
    "embedding = Embedding(max_words, EMBEDDING_DIM, input_length=maxlen, trainable=False)\n",
    "#embedding = Embedding(word_indices_len + 1, EMBEDDING_DIM,input_length=MAX_SEQUENCE_LENGTH + pre_padding, trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    # Create model\n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(embedding)\n",
    "    model.add(Conv1D(32,5, activation='relu'))\n",
    "    model.add(Flatten()) #3D to 2D\n",
    "    #model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(4, activation='softmax'))\n",
    "    #model.summary()\n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(embedding)\n",
    "    model.add(Conv1D(32,5, activation='relu'))\n",
    "    model.add(layers.Bidirectional(layers.LSTM(32,dropout=0.4, recurrent_dropout=0.4,)))\n",
    "    #model.add(Dense(8, activation='relu'))\n",
    "    #model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(4, activation='softmax'))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run x Times the folds\n",
    "for run_num in range(1,fold_runs+1):\n",
    "    # k-fold\n",
    "    for train_ind, val_ind in skfold.split(x_train,y_train):\n",
    "\n",
    "        # Create model\n",
    "        model = create_model()\n",
    "\n",
    "        # Load GloVe embedding\n",
    "        model.layers[0].set_weights([word_embedding_matrix])\n",
    "        model.layers[0].trainable = False\n",
    "\n",
    "        # Train and Evaluate\n",
    "        model.compile(optimizer='adam',\n",
    "                    loss='sparse_categorical_crossentropy',\n",
    "                    metrics=['acc'])\n",
    "        print('------------------------------------------------------------------------')\n",
    "        print(f'Training for fold {fold_no} ind run {run_num} ...')\n",
    "\n",
    "        history = model.fit(x_train[train_ind], y_train[train_ind],\n",
    "                            epochs=epochs,\n",
    "                            batch_size=32,\n",
    "                            verbose=1,\n",
    "                            validation_data=(x_train[val_ind], y_train[val_ind]))\n",
    "\n",
    "        # metrics\n",
    "        scores = model.evaluate(x_train[val_ind], y_train[val_ind], batch_size=128)\n",
    "        #print(f'Score for fold {fold_no}: {model.metrics_name[0]} of {scores[0]}; {model.metrics_name[1]} of {scores[1]*100}%')\n",
    "        print(f'Score for fold {fold_no}: ... of {scores[0]}; ... of {scores[1]*100}%')\n",
    "        acc_per_fold.append(scores[1]*100)\n",
    "        loss_per_fold.append(scores[0])\n",
    "\n",
    "        fold_no += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # == Provide average scores ==\n",
    "    print('------------------------------------------------------------------------')\n",
    "    print('Score per fold')\n",
    "    for i in range(0, len(acc_per_fold)):\n",
    "        print('------------------------------------------------------------------------')\n",
    "        print(f'> Fold {i+1} - Loss: {loss_per_fold[i]} - Accuracy: {acc_per_fold[i]}%')\n",
    "    print('------------------------------------------------------------------------')\n",
    "    print('Average scores for all folds:')\n",
    "    avg_acc_per_run.append(np.mean(acc_per_fold))\n",
    "    avg_loss_per_run.append(np.mean(loss_per_fold))\n",
    "    print(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\n",
    "    print(f'> Loss: {np.mean(loss_per_fold)}')\n",
    "    print('------------------------------------------------------------------------')\n",
    "\n",
    "    # reset fold vars\n",
    "    acc_per_fold = []\n",
    "    loss_per_fold = []\n",
    "    fold_no = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# == Provide average scores ==\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Score per fold')\n",
    "for i in range(0, len(avg_acc_per_run)):\n",
    "    print('------------------------------------------------------------------------')\n",
    "    print(f'> Run {i+1} Fold averages - Loss: {avg_loss_per_run[i]} - Accuracy: {avg_acc_per_run[i]}%')\n",
    "print('------------------------------------------------------------------------')\n",
    "print(f'Overall average scores for all {fold_runs} runs:')\n",
    "\n",
    "print(f'> Accuracy: {np.mean(avg_acc_per_run)} (+- {np.std(avg_acc_per_run)})')\n",
    "print(f'> Loss: {np.mean(avg_loss_per_run)}')\n",
    "print('------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------\n",
      "Score per fold\n",
      "------------------------------------------------------------------------\n",
      "Overall average scores for all 1 runs:\n",
      "> Accuracy: nan (+- nan)\n",
      "> Loss: nan\n",
      "------------------------------------------------------------------------\n",
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 100, 1560)         15600000  \n",
      "_________________________________________________________________\n",
      "conv1d_15 (Conv1D)           (None, 96, 32)            249632    \n",
      "_________________________________________________________________\n",
      "bidirectional_15 (Bidirectio (None, 64)                16640     \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 4)                 260       \n",
      "=================================================================\n",
      "Total params: 15,866,532\n",
      "Trainable params: 266,532\n",
      "Non-trainable params: 15,600,000\n",
      "_________________________________________________________________\n",
      "------------------------------------------------------------------------\n",
      "Training for final model ...\n",
      "Train on 1620 samples, validate on 180 samples\n",
      "Epoch 1/10\n",
      "1620/1620 [==============================] - 6s 4ms/step - loss: 1.4016 - acc: 0.3012 - val_loss: 1.3488 - val_acc: 0.3444\n",
      "Epoch 2/10\n",
      "1620/1620 [==============================] - 5s 3ms/step - loss: 1.2952 - acc: 0.3840 - val_loss: 1.3633 - val_acc: 0.3611\n",
      "Epoch 3/10\n",
      "1620/1620 [==============================] - 5s 3ms/step - loss: 1.2498 - acc: 0.4327 - val_loss: 1.3581 - val_acc: 0.3833\n",
      "Epoch 4/10\n",
      "1620/1620 [==============================] - 5s 3ms/step - loss: 1.1936 - acc: 0.4660 - val_loss: 1.3391 - val_acc: 0.3389\n",
      "Epoch 5/10\n",
      "1620/1620 [==============================] - 5s 3ms/step - loss: 1.1557 - acc: 0.4846 - val_loss: 1.4268 - val_acc: 0.3611\n",
      "Epoch 6/10\n",
      "1620/1620 [==============================] - 5s 3ms/step - loss: 1.1162 - acc: 0.5123 - val_loss: 1.4314 - val_acc: 0.3222\n",
      "Epoch 7/10\n",
      "1620/1620 [==============================] - 5s 3ms/step - loss: 1.0631 - acc: 0.5370 - val_loss: 1.4920 - val_acc: 0.3000\n",
      "Epoch 8/10\n",
      "1620/1620 [==============================] - 5s 3ms/step - loss: 1.0552 - acc: 0.5426 - val_loss: 1.4759 - val_acc: 0.2944\n",
      "Epoch 9/10\n",
      "1620/1620 [==============================] - 5s 3ms/step - loss: 1.0171 - acc: 0.5710 - val_loss: 1.5670 - val_acc: 0.3222\n",
      "Epoch 10/10\n",
      "1620/1620 [==============================] - 5s 3ms/step - loss: 0.9978 - acc: 0.5722 - val_loss: 1.6606 - val_acc: 0.3056\n",
      "Evaluate final model on test data\n",
      "180/180 [==============================] - 0s 561us/step\n",
      "test loss, test acc: [1.6605535719129774, 0.3055555522441864]\n"
     ]
    }
   ],
   "source": [
    "# run x Times the folds\n",
    "if not run_final_train_only:\n",
    "    for run_num in range(1,fold_runs+1):\n",
    "        # k-fold\n",
    "        for train_ind, val_ind in skfold.split(x_train,y_train):\n",
    "\n",
    "            # Create model\n",
    "            model = create_model()\n",
    "\n",
    "            # Load GloVe embedding\n",
    "            model.layers[0].set_weights([word_embedding_matrix])\n",
    "            model.layers[0].trainable = False\n",
    "\n",
    "            # Train and Evaluate\n",
    "            model.compile(optimizer='adam',\n",
    "                        loss='sparse_categorical_crossentropy',\n",
    "                        metrics=['acc'])\n",
    "            print('------------------------------------------------------------------------')\n",
    "            print(f'Training for fold {fold_no} ind run {run_num} ...')\n",
    "\n",
    "            history = model.fit(x_train[train_ind], y_train[train_ind],\n",
    "                                epochs=epochs,\n",
    "                                batch_size=32,\n",
    "                                verbose=1,\n",
    "                                validation_data=(x_train[val_ind], y_train[val_ind]))\n",
    "\n",
    "            # metrics\n",
    "            scores = model.evaluate(x_train[val_ind], y_train[val_ind], batch_size=32)\n",
    "            #print(f'Score for fold {fold_no}: {model.metrics_name[0]} of {scores[0]}; {model.metrics_name[1]} of {scores[1]*100}%')\n",
    "            print(f'Score for fold {fold_no}: loss of {scores[0]}; accuracy of {scores[1]*100}%')\n",
    "            acc_per_fold.append(scores[1]*100)\n",
    "            loss_per_fold.append(scores[0])\n",
    "\n",
    "            fold_no += 1\n",
    "\n",
    "\n",
    "        # == Provide average scores ==\n",
    "        print('------------------------------------------------------------------------')\n",
    "        print('Score per fold')\n",
    "        for i in range(0, len(acc_per_fold)):\n",
    "            print('------------------------------------------------------------------------')\n",
    "            print(f'> Fold {i+1} - Loss: {loss_per_fold[i]} - Accuracy: {acc_per_fold[i]}%')\n",
    "        print('------------------------------------------------------------------------')\n",
    "        print('Average scores for all folds:')\n",
    "        avg_acc_per_run.append(np.mean(acc_per_fold))\n",
    "        avg_loss_per_run.append(np.mean(loss_per_fold))\n",
    "        print(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\n",
    "        print(f'> Loss: {np.mean(loss_per_fold)}')\n",
    "        print('------------------------------------------------------------------------')\n",
    "\n",
    "        # reset fold vars\n",
    "        acc_per_fold = []\n",
    "        loss_per_fold = []\n",
    "        fold_no = 1\n",
    "\n",
    "# == Provide average scores ==\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Score per fold')\n",
    "for i in range(0, len(avg_acc_per_run)):\n",
    "    print('------------------------------------------------------------------------')\n",
    "    print(f'> Run {i+1} Fold averages - Loss: {avg_loss_per_run[i]} - Accuracy: {avg_acc_per_run[i]}%')\n",
    "print('------------------------------------------------------------------------')\n",
    "print(f'Overall average scores for all {fold_runs} runs:')\n",
    "\n",
    "print(f'> Accuracy: {np.mean(avg_acc_per_run)} (+- {np.std(avg_acc_per_run)})')\n",
    "print(f'> Loss: {np.mean(avg_loss_per_run)}')\n",
    "print('------------------------------------------------------------------------')\n",
    "\n",
    "# create final model #Todo sync with fold rund\n",
    "if create_final_model:\n",
    "    model = create_model()\n",
    "    model.summary()\n",
    "\n",
    "    # Load GloVe embedding\n",
    "    model.layers[0].set_weights([word_embedding_matrix])\n",
    "    model.layers[0].trainable = False\n",
    "\n",
    "    # Train and Evaluate\n",
    "    model.compile(optimizer='adam',\n",
    "                loss='sparse_categorical_crossentropy',\n",
    "                metrics=['acc'])\n",
    "    print('------------------------------------------------------------------------')\n",
    "    print('Training for final model ...')\n",
    "\n",
    "    history = model.fit(x_train_copy, y_train_copy,\n",
    "                        epochs=epochs,\n",
    "                        batch_size=32,\n",
    "                        verbose=1,\n",
    "                        validation_data=(x_test, y_test))\n",
    "    # Save Model\n",
    "    if use_mg_train_corpora:\n",
    "        model.save('models/model_emotion_detection_multigenre.h5')\n",
    "    else:\n",
    "        model.save('models/model_emotion_detection_twitter.h5')\n",
    "\n",
    "    # Test final model\n",
    "    print(\"Evaluate final model on test data\")\n",
    "    results = model.evaluate(x_test, y_test, batch_size=128)\n",
    "    print(\"test loss, test acc:\", results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------\n",
      "Score per fold\n",
      "------------------------------------------------------------------------\n",
      "Overall average scores for all 1 runs:\n",
      "> Accuracy: nan (+- nan)\n",
      "> Loss: nan\n",
      "------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# == Provide average scores ==\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Score per fold')\n",
    "for i in range(0, len(avg_acc_per_run)):\n",
    "    print('------------------------------------------------------------------------')\n",
    "    print(f'> Run {i+1} Fold averages - Loss: {avg_loss_per_run[i]} - Accuracy: {avg_acc_per_run[i]}%')\n",
    "print('------------------------------------------------------------------------')\n",
    "print(f'Overall average scores for all {fold_runs} runs:')\n",
    "\n",
    "print(f'> Accuracy: {np.mean(avg_acc_per_run)} (+- {np.std(avg_acc_per_run)})')\n",
    "print(f'> Loss: {np.mean(avg_loss_per_run)}')\n",
    "print('------------------------------------------------------------------------')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['anger', 'fear', 'joy', 'sadness']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3055555555555556"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict_classes(x_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.rcParams.update(matplotlib.rcParamsDefault)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.rc('font', family = 'Serif')\n",
    "\n",
    "mat = confusion_matrix(y_test, y_pred)\n",
    "fig, ax = plot_confusion_matrix(conf_mat=mat, figsize=(6,6), class_names = class_names, show_normed=False)\n",
    "plt.tight_layout()\n",
    "fig.savefig('cm.png')\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-65-c73d89358832>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-65-c73d89358832>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    sklearn.metrics.f1_score(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')\u001b[0m\n\u001b[1;37m                                              ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "sklearn.metrics.f1_score(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gputest",
   "language": "python",
   "name": "gputest"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
